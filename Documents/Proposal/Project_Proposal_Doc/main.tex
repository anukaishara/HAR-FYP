\documentclass[12pt, a4paper, oneside]{report}
\usepackage{graphicx} % For including images
\usepackage{titlesec} % For customizing section titles
\usepackage{tocloft} % For customizing table of contents
\usepackage{acro} % For acronyms
\usepackage{enumitem}
\usepackage{placeins} % For \FloatBarrier
\usepackage{float} % For [H] float placement
\usepackage{caption} % For caption alignment control
\usepackage{tabularx} % For tables that fit \textwidth
\usepackage{array} % For column definitions in tabularx
\usepackage{etoolbox} % For \patchcmd
%% ____Bibliography____%%
\usepackage[numbers,sort&compress]{natbib}
\usepackage{chapterbib}
\usepackage[breaklinks]{hyperref} % For clickable links in the document
%\hypersetup{colorlinks=true,citecolor=blue,linkcolor=blue,urlcolor=blue}
% Page margins
\usepackage[left=1.5in, right=1in, top=1in, bottom=1in]{geometry}

% Consistent numbering styles (no bullet lists)
\setlist[enumerate,1]{label=\arabic*., leftmargin=*}
\setlist[enumerate,2]{label=\alph*), leftmargin=*}
\setlist[enumerate,3]{label=\roman*), leftmargin=*}

% Avoid blank pages created when a \chapter starts at the top of an already-cleared page
\makeatletter
\newcommand{\clearpageifnotempty}{\ifdim\pagetotal=0pt\else\clearpage\fi}
\patchcmd{\chapter}{\if@openright\cleardoublepage\else\clearpage\fi}{\if@openright\cleardoublepage\else\clearpageifnotempty\fi}{}{}
\makeatother

% Customize table of contents, list of figures, and list of tables
\renewcommand{\cfttoctitlefont}{\hfill\Large\bfseries}
\renewcommand{\cftaftertoctitle}{\hfill}
\renewcommand{\cftloftitlefont}{\hfill\Large\bfseries}
\renewcommand{\cftafterloftitle}{\hfill}
\renewcommand{\cftlottitlefont}{\hfill\Large\bfseries}
\renewcommand{\cftafterlottitle}{\hfill}

% Define acronyms
\DeclareAcronym{AI}{
  short = AI,
  long  = Artificial Intelligence
}

\DeclareAcronym{AMASS}{
  short = AMASS,
  long  = Archive of Motion Capture as Surface Shapes
}

\DeclareAcronym{API}{
  short = API,
  long  = Application Programming Interface
}

\DeclareAcronym{AR}{
  short = AR,
  long  = Augmented Reality
}

\DeclareAcronym{biRNN}{
  short = biRNN,
  long  = Bidirectional Recurrent Neural Network
}

\DeclareAcronym{CoM}{
  short = CoM,
  long  = Center of Mass
}

\DeclareAcronym{DIP}{
  short = DIP,
  long  = Deep Inertial Poser
}

\DeclareAcronym{DNN}{
  short = DNN,
  long  = Deep Neural Networks
}

\DeclareAcronym{ECE}{
  short = ECE,
  long  = Expected Calibration Error
}

\DeclareAcronym{FID}{
  short = FID,
  long  = Fréchet Inception Distance
}

\DeclareAcronym{FIP}{
  short = FIP,
  long  = Fast Inertial Poser
}

\DeclareAcronym{FPS}{
  short = FPS,
  long  = Frames Per Second
}

\DeclareAcronym{FSR}{
  short = FSR,
  long  = Foot Sliding Ratio
}

\DeclareAcronym{GPU}{
  short = GPU,
  long  = Graphics Processing Unit
}

\DeclareAcronym{HMR}{
  short = HMR,
  long  = Human Mesh Recovery
}

\DeclareAcronym{IK}{
  short = IK,
  long  = Inverse Kinematics
}

\DeclareAcronym{IMU}{
  short = IMU,
  long  = Inertial Measurement Unit
}

\DeclareAcronym{LBS}{
  short = LBS,
  long  = Linear Blend Skinning
}

\DeclareAcronym{LPIPS}{
  short = LPIPS,
  long  = Learned Perceptual Image Patch Similarity
}

\DeclareAcronym{ML}{
  short = ML,
  long  = Machine Learning
}

\DeclareAcronym{MPJPE}{
  short = MPJPE,
  long  = Mean Per Joint Position Error
}

\DeclareAcronym{PA-MPJPE}{
  short = PA-MPJPE,
  long  = Procrustes-Aligned Mean Per Joint Position Error
}

\DeclareAcronym{PD}{
  short = PD,
  long  = Proportional Derivative
}

\DeclareAcronym{PIFu}{
  short = PIFu,
  long  = Pixel-aligned Implicit Function
}

\DeclareAcronym{PIP}{
  short = PIP,
  long  = Physical Inertial Poser
}

\DeclareAcronym{PCA}{
  short = PCA,
  long  = Principal Component Analysis
}

\DeclareAcronym{PSD}{
  short = PSD,
  long  = Pose Space Deformation
}

\DeclareAcronym{PVE}{
  short = PVE,
  long  = Per Vertex Error
}

\DeclareAcronym{RGB}{
  short = RGB,
  long  = Red Green Blue
}

\DeclareAcronym{RNN}{
  short = RNN,
  long  = Recurrent Neural Network
}

\DeclareAcronym{ROMP}{
  short = ROMP,
  long  = Regressing Monocular 3D Pose and Shape
}

\DeclareAcronym{SIP}{
  short = SIP,
  long  = Sparse Inertial Poser
}

\DeclareAcronym{SMPL}{
  short = SMPL,
  long  = Skinned Multi-Person Linear Model
}

\DeclareAcronym{TIP}{
  short = TIP,
  long  = Transformer Inertial Poser
}

\DeclareAcronym{VR}{
  short = VR,
  long  = Virtual Reality
}


\begin{document}

\include{cover}

\renewcommand{\thepage}{\roman{page}} % Start page numbering in roman

\chapter*{Abstract}
Human activity reconstruction is widely used in the health industry, sports, rehabilitation, and virtual reality platforms. Traditional motion capture technology often relies on multiple inertial sensors including accelerometers, gyroscopes, as well as magnetometers, increasing the cost, complexity, and the power consumption.
This project presents a simplified human activity reconstruction system using a sparse sensor configuration with only five 3-axis accelerometer sensors placed on the wrists, ankles, and torso which is designed as a simple wearable device. Machine learning algorithms are employed for recognizing patterns in human movement from the 15 accelerometer reading we are obtaining for a certain time period, and inverse kinematics is employed to model overall human movement. Our main aim is to represent the reconstructed model as a customized 3D avatar motion based on the body dimensions. Therefore, the proposed approach demonstrates a low cost and simple wearable alternative to conventional human activity reconstruction systems.

\newpage

% Table of Contents
\tableofcontents
\newpage

% List of Figures
\listoffigures
\newpage

% List of Tables
\listoftables
\newpage

% Acronyms
\addcontentsline{toc}{chapter}{Acronyms} % Add to table of contents
\acuseall % Use all acronyms to ensure they appear in the list
\printacronyms
\newpage

\renewcommand{\thepage}{\arabic{page}} % Start page numbering in arabic 
\setcounter{page}{1} % start page numbering from 1

% Main Content
\chapter{Introduction}
\section{Background}
\noindent Human activity reconstruction of a user’s 3D skeletal configuration has become increasingly important for analyzing and visualizing human movement in areas such as healthcare, sports analysis, rehabilitation, virtual reality, gaming, biomechanical analysis and immersive human computer interaction including virtual and augmented reality since it enables remote monitoring and evaluation. Also,the approach of reconstructing human motion using movement data rather than using video data helps to preserve the privacy of the users of these systems. These systems must function reliably in everyday environments and minimize the intrusiveness and user instrumentation.\vspace{\baselineskip}

\noindent Traditional motion capture systems rely on high-end optical based setups with multiple cameras, markers such as Vicon, and high accuracy inertial sensors, which require expensive infrastructure, controlled environments, and complex setups to attach them to the body, making them unsuitable for portable or everyday use.\vspace{\baselineskip}

\noindent Sensor based approaches that mount devices directly on the human body can overcome the line-of-sight limitations of the vision based methods. Hence, Inertial Measurement Units (\ac{IMU}s), which provide acceleration and orientation data are proposed due to their low power consumption and ease of wearability. Dense inertial configurations, typically using more than 17 \ac{IMU}s placed near major joints, can directly estimate a joint's orientation. Therefore, these systems rely heavily on sensor accuracy. Even though there are commercial solutions based on this system like Xsens, dense \ac{IMU} setups are intrusive, uncomfortable to wear and require extensive calibration making them undesirable for consumer level usages\cite{yi2021transpose}.\vspace{\baselineskip}

\noindent In contrast, recent research shows that sparse sensor configurations can effectively capture motion by using the lesser number of sensors which are placed on the key segments of the body. The reduced number of sensors leads to insufficient joint constraints, making the motion reconstruction more complex. The \ac{IMU}s itself is incapable of measuring the distances directly and the early sparse \ac{IMU} methods primarily based on optimization approaches which the human motion was reconstructed by matching sensor data to pre recorded motion datasets or by solving constrained convex or nonconvex optimization problems using physical and kinematic constraints. Therefore, these methods require high computational power and present significant latency making these unsuitable for real time applications.\vspace{\baselineskip}

\noindent To address these limitations, learning based methods using Deep Neural Networks (\ac{DNN}s) have been proposed and Deep Inertial Poser (\ac{DIP}) was one of the earliest learning based method used to directly map sparse \ac{IMU} data to full body pose using \ac{DNN}s and large scale training datasets. \ac{DIP} significantly improved the real time performance which was a challenge in earlier times but still had some limitations in accuracy and recreation of the complex motions. Then , the Transformer Inertial Poser (\ac{TIP}) introduced transformer architectures combined with sampling based optimization to capture long term temporal dependencies in motion data improving the reconstruction quality but the computational cost was increased. Physical Inertial Poser (\ac{PIP}) further incorporated physical constraints and torque modeling through dual proportional derivative (\ac{PD}) controllers to model the torque and optimize the output of the transpose. But this additional optimization layer increases the computational burden and reduces the suitability for resource constrained platforms.\vspace{\baselineskip}

\noindent For real-world applications involving consumers, motion capture systems should be able to operate within mobile platforms such as \ac{AR}-\ac{VR} Headsets, Smart Glasses, or wearable technology that impose tight power, size, and processing resource constraints. More importantly, most of the current approaches haven’t considered body shape information. This disregard causes bias to body shapes and adds to computational costs involved in pose estimation.\vspace{\baselineskip}

\noindent Then the Fast Inertial Poser (\ac{FIP}) was proposed which is a real time motion capture method which can reduce the computational burden and latency while increasing the accuracy of the human activity reconstruction making it more suitable for embedded platforms with limited computational power and also it consider the body measurements of the user before wearing the device.\vspace{\baselineskip}

\noindent Also, the coupling of Machine Learning (\ac{ML}) methods and biomechanical modeling has emerged as a successful strategy for the estimation of correct 3D skeletal poses using noisy and incomplete sensor data. From the point of view of \ac{IMU}-based motion capture systems, Machine Learning models can be trained to learn the complex, generally nonlinear relations between the sensor data (Inertial measurements of orientation, Angular Velocity, and Acceleration) and the corresponding joint orientations of the human body. Using the prior knowledge of human motion learned by Machine Learning systems, it is possible to overcome the ambiguities inherent to the application of incomplete sensor setups and noisy sensor readings.\vspace{\baselineskip}

\noindent With joint orientation/pose parameters estimated by \ac{ML} algorithms, a full-body skeletal reconstruction is often obtained via Inverse Kinematics (\ac{IK}). It imposes constraints such as bone length, joint limits, and body part hierarchical order to ensure a valid skeletal reconstruction that is not only meaningful in a physical sense but anatomically feasible as well. Thus, \ac{ML} is used for a problem that is undetermined yet important for pose reconstruction and temporal consistency of the reconstruction sequence, and \ac{IK} is then used to refine the final reconstruction and prepare it for visualization purposes.\vspace{\baselineskip}

\noindent The synergy of \ac{ML}-based pose estimation and inverse kinematics is even more valuable for real-time computation on embedded systems. \ac{ML} inference is fast once the model is trained, and \ac{IK} is a light Post-processing step that maintains human body consistency with relatively inexpensive global optimization. Thus, these two combined can make skeletal data generation from sparse \ac{IMU} highly efficient for minimally invasive and real-time motion capture systems used for applications like \ac{VR}/\ac{AR}, gaming, and human-computer interaction\cite{xiao2024fast}.
\vspace{\baselineskip}


\section{Problem Statement}

\noindent Even though human activity reconstruction is carried out using wearable motion capture systems in areas such as healthcare, sports, virtual reality, and rehabilitation. Most existing \ac{IMU}-based motion capture approaches rely on multiple sensors incorporating accelerometers and gyroscopes to estimate body orientation and joint movements with high accuracy. Commercial systems such as Xsens MVN and perception neuron typically employ 10-17 \ac{IMU}s leading to increased hardware cost, complex calibration procedures and higher computational requirements for sensor fusion and drift compensation making such systems less suitable for simple and low hardware cost wearable solutions.\vspace{\baselineskip}

\noindent Gyroscope-based motion reconstruction involves sensor fusion, calibration processes, and drift compensation algorithms which increases the computational power, power consumption and the design complexity. Also, over time the drift will accumulate and this leads to inaccuracies in the orientation which affects the precision of the reconstruction over longer spans of the activity. Furthermore, when a larger number of gyroscope and accelerometer equipped sensors are used, it reduces the wearability and simplicity, making them uncomfortable for users and impractical for everyday or long-term use.\vspace{\baselineskip}

\noindent Considering all these limitations, a simple, low cost and minimally intrusive system approach is needed for human activity reconstruction. Therefore, the challenge is to utilize a sparse set of accelerometer only sensors and combine evolving engineering technologies in order to reconstruct meaningful human motion while maintaining affordability, simplicity, and user comfort.\vspace{\baselineskip}

\section{Objectives and Scope}

\subsection{Aim}

\noindent Develop a low cost and simple wearable accelerometer based human activity reconstruction system that accurately estimates the movements of the joints and reconstructs the full body motion and visualizes it through a personalized 3D avatar while validating the reconstructed motion against synchronized reference video data.\vspace{\baselineskip}

\subsection{Objectives}

\noindent The specific objectives of the project are as follows,
\vspace{\baselineskip}

\begin{enumerate}[leftmargin=*, itemsep=1em]
    \item{Accurately acquire raw time synchronized motion data from the user during movement} \\
    \textit{Expected outcome} -- Accurate accelerometer-based sensor readings with synchronized timestamps representing the user's physical movement to be used for further processing.

    \item {Design and develop a method to estimate joint postures and orientations using the collected raw accelerometer data} \\
    \textit{Expected outcome} -- Accurate joint posture parameters, such as joint angles and orientations, that represent the user's physical movement for use in skeletal mapping.

    \item {Design a skeletal model using joint posture parameters and create a 3D avatar} \\
    \textit{Expected outcome} -- A realistic, 3D human avatar that reconstructs the full-body motion of the user's physical movement.

    \item {Design and implement a subsystem to validate the reconstructed human activity and the avatar output through a reliable evaluation method} \\
    \textit{Expected outcome} -- Validation results representing the accuracy, consistency, plausibility, and reliability of the human activity reconstruction system.
\end{enumerate}
\vspace{\baselineskip}

\subsection{Scope}
\begin{enumerate}[leftmargin=*, itemsep=1.5em]
    \item Development of computational methods to estimate the posture or the movement of the human body using only accelerometer data, without reliance on gyroscopes or magnetometers. To compensate for the limited input which utilizes only 5 accelerometer based sensors, advanced predictive and calculative methods will be needed. Therefore, due to computational latency and processing constraints, real time motion reconstruction will not be feasible. Consequently, the system operates in an offline capacity; data is recorded during the session and manually processed post-hoc for activity reconstruction.
    
    \item Integration of estimated posture or the movement into a skeletal kinematic model for a high fidelity representation of the user’s movements.
    
    \item Creation of a personalized 3D human avatar that animates the reconstructed skeletal motion, incorporating skin generation based on individual user parameters such as limb lengths, body proportions and skin tone providing a realistic visual representation of the user’s physical movements while enhancing the user experience. However, a primary limitation of the current model is the absence of fine-grained joint articulation-specifically finger movements, subtle rotational variances, and head orientation as the reconstruction is constrained by the sparse five-sensor input.
    
    \item Design and implementation of a dedicated validation subsystem that utilizes a synchronized video feed as the ground-truth reference. The validation process involves a side-by-side comparison of the raw video footage against the reconstructed avatar motion. This subsystem focuses on qualitative assessment and approximate accuracy rather than exhaustive quantitative precision, as the primary objective is to validate the model's architectural integrity from a visualization perspective. The validation process may be limited by the availability, synchronization accuracy and quality of reference video data or ground-truth motion capture systems.
\end{enumerate}

\chapter{Literature Review}

\section{Previous Work}

\subsection{Developing the Models using Sparse \ac{IMU}s to Estimate the Joint Postures and the Orientations}
\ac{IMU}-based human activity reconstruction aims to model full-body pose while avoiding the limitations of camera-based systems. Over time, research on this topic has evolved from optimization-based approaches to deep learning models while reducing the number of sensors, computational power, cost, and improving durability. \ac{SIP}, \ac{DIP}, \ac{TIP}, \ac{PIP}, and \ac{FIP} represent key milestones along this research journey.

\subsubsection*{(a) Sparse Inertial Poser (\ac{SIP})}
\ac{SIP} is an optimization-based method that formulates pose estimation as a global or temporal optimization problem using motion priors and kinematic constraints. Although this method achieves high accuracy with sparse \ac{IMU}s, it is computationally expensive and exhibits higher latency, which limits its applicability in real-time and mobile systems \cite{yi2021transpose}.

\subsubsection*{(b) Deep Inertial Poser (\ac{DIP})}
\ac{DIP} employs bidirectional \ac{RNN}s to estimate joint rotations from \ac{IMU} data, incorporating learned kinematic constraints to achieve faster inference compared to \ac{SIP} while maintaining good accuracy.However, this system is not suitable for real time applications because of the non causal inference and the latency of the system where it is depending on past and future frames. \cite{huang2018deep}. Figure~\ref{fig:dip_pipeline} illustrates the overview of the \ac{DIP} pipeline.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{Overview of the DIP pipeline.png}
    \caption{Overview of the DIP pipeline}
    \label{fig:dip_pipeline}
\end{figure}

\subsubsection*{(c) Transformer Inertial Poser (\ac{TIP})}
\ac{TIP} is a transformer based system which can handle complex motions accurately since it captures long range temporal dependencies without using inverse kinematics solver. But this system requires high computational power and memory resources limiting the usage in embedded and wearable applications. \cite{yi2021transpose}.Figure~\ref{fig:tip_pipeline} presents the overview of the \ac{TIP} pipeline.


\begin{figure}[H]
    \centering
  \includegraphics[angle=90,origin=c,width=0.4\textwidth,height=0.39\textheight]{Overview of the TIP pipeline.png}
    \caption{Overview of the TIP pipeline}
    \label{fig:tip_pipeline}
\end{figure}

\newpage

\subsubsection*{(d) Physics-based Inertial Poser (\ac{PIP})}
\ac{PIP} is a physics-based model with optimization and inverse kinematics to enhance the balance constraints and ground contact consistency. This system has improved realistic human motion reconstruction and contact handling than the learning based models. But high computational power and complex system design limits the real time applicability\cite{xiao2024fast}.

\subsubsection*{(e) Fast Inertial Poser (\ac{FIP})}
\ac{FIP} is a real time human motion reconstruction model which estimates full body motion using only six sparse \ac{IMU}s while considering the human body shape information. This model uses a bidirectional \ac{RNN} that and enables low-latency inference. Body parameters such as height and limb lengths help resolve pose ambiguities caused by sparse sensing. Experimental validation on the \ac{AMASS} and \ac{DIP}-\ac{IMU} datasets demonstrates state-of-the-art performance, achieving over 60~\ac{FPS} with less than 15~ms latency \cite{xiao2024fast}. Figure \ref{fig:fip_illustration} shows the overview of the \ac{FIP} pipeline.



\begin{figure}[H]
    \centering
  \includegraphics[origin=c,width=0.9\textwidth,height=0.9\textheight,keepaspectratio]{Illustration of FIP.png}
    \caption{Illustration of FIP}
    \label{fig:fip_illustration}
\end{figure}

\FloatBarrier

\newpage
\subsection{Developing the Models using Accelerometers to Estimate the Joint Postures and the Orientations}
\begin{enumerate}[leftmargin=*, itemsep=1em]
    \item Human activity reconstruction for full-body pose has been performed using only four sparse 3-axis accelerometers placed on the wrists and ankles. Instead of using accelerometer readings directly, which can introduce significant drift, this method used a data-driven approach leveraging a large motion capture database. A simulate-and-optimize approach was utilized to generate synthesized accelerometer readings to align with sensor data through nearest-neighbor search and graph optimization. Inverse kinematics and reduced-dimensional pose representations were used to recover plausible full-body poses in real-time \cite{tautges2011motion}. Following Figure~\ref{fig:tautges2011} shows the overview of the system proposed in tautges 2011.

    \begin{figure}[!htbp]
        \centering
        \includegraphics[width=0.95\textwidth]{Overview of the system proposed in tautges 2011.png}
        \caption{Overview of the system proposed in tautges 2011}
        \label{fig:tautges2011}
    \end{figure}
  
    \item Human motion can also be reconstructed using wearable accelerometers in complete isolation from the requirement for optical motion capture systems. A portable, low-cost framework where several body-mounted tri-axial accelerometers were used to estimate full-body motion, especially for sports and outdoors for which optical systems are impractical. Instead of directly computing the joint angles from sensor data, their approach relies on a data-driven motion database and a motion graph constructed from pre-recorded motion capture data. On this database, virtual accelerometers were simulated, and a dynamic programming–based matching algorithm was used for finding pose sequences whose simulated accelerations best matched the measured sensor readings. While the method indeed produced naturalistic motions using only accelerometer data, it was prone to positional drift over time, showing one major limitation of accelerometer-based motion reconstruction approaches.\cite{kelly2010human} Following Figure~\ref{fig:kelly2010} shows the overview of the system proposed in kelly 2010.

\begin{figure}[!htbp]
    \centering
    \includegraphics[
        width=0.8\textwidth,
        height=0.8\textheight,
        keepaspectratio]{Overview of the system proposed in kelly 2010.png}
    \caption{Overview of the system proposed in Kelly (2010)}
    \label{fig:kelly2010}
\end{figure}

\end{enumerate}

\FloatBarrier

\subsection{Human Activity Detection Using WWSN and Artificial Intelligence}
Beyond skeletal pose estimation, localized research has demonstrated the efficacy of a Wearable Wireless Sensor Network (WWSN) for direct activity classification using sparse accelerometer data. This study, from the University of Ruhuna, accurately differentiated six specific physical activities: cycling, pushups, running, squats, walking, and table tennis. The study also aimed to discover the optimal configurations of the sensors to lessen the burden placed on the user.

The research developed two distinct paradigms for activity classification based on the dependencies they capture:
\begin{enumerate}[leftmargin=*, itemsep=1em]
    \item Detection by Capturing Spatial Dependencies: When an activity is seen as a single snapshot of sensor readings, conventional machine learning approaches are used. The Random Forest Classifier (RFC) outperformed KNN, SVM, and Naïve Bayes, with an accuracy of over 96\%.
    \item Detection by Capturing Spatial and Temporal Dependencies: For activities defined as a series of instances, Convolutional Neural Networks (CNNs) were used to capture complex physical movements over time. This strategy achieved an accuracy and F1-score of more than 97\%.
    
  A key conclusion of this study was the identification of wrist sensors (Sensor IDs 1 and 4) as the most significant pair for classifying target activities. \cite{gunawardena2025wsn}. The results show that a reduced arrangement of two sensors can give reliable activity recognition with only slight reduction in performance, provided the models are trained on a balanced and sufficiently large dataset. Following Figure \ref{fig:WWSN_axes_accelerometer} shows the sensor positioning of WWSN and the three axes of accelerometer.
    \begin{figure}[!htbp]
        \centering
        \includegraphics[width=0.95\textwidth]{Sensor positioning of WWSN and 3 axes of accelerometer.png}
        \caption{Sensor positioning of WWSN and the three axes of accelerometers.}
        \label{fig:WWSN_axes_accelerometer}
    \end{figure}
    \newpage  

\end{enumerate}

\FloatBarrier

\subsection{3D Skeletal Reconstruction using Parametric Pose Angles}
Traditional motion capture often relies on deriving absolute 3D coordinates ($x, y, z$) for individual joints. However, for applications requiring high anatomical fidelity, simple coordinate-based methods are insufficient as they lack surface information and rigid biomechanical constraints. Parametric skeletal reconstruction addresses these limitations by estimating pose angles of a digital skin. This approach ensures reconstructed motion adheres to physiological limits and serves as the foundation for "Digital Twin" technologies.

\subsubsection*{SMPLify (Skinned Multi-Person Linear Model)}
The SMPL model is a vertex-based statistical model defining the human body surface. It is parametric, controlled by two low-dimensional vectors: Shape ($\beta$), representing coefficients derived from PCA, and Pose ($\theta$), representing axis-angle rotations of joints in a kinematic tree. The skin consists of 6,890 vertices bound using Linear Blend Skinning (LBS) weights \cite{loper2015smpl}. The effectiveness of this reconstruction approach is illustrated in Figure \ref{fig:smplify_eval}, which demonstrates the SMPLify model's performance across varying accuracy percentiles. 

\begin{enumerate}[leftmargin=*]
    \item \textbf{Mathematical Formulation} \\
    The body mesh is a function of shape ($\beta$) and pose ($\theta$):
  \begin{enumerate}[leftmargin=*]
        \item \textbf{Shape ($\beta$)} \\
        A vector of 10 coefficients derived from Principal Component Analysis (PCA) of body scans. Changing these values alters the subject's height, weight, and muscularity without affecting their pose.
        
        \item \textbf{Pose ($\theta$)} \\
        A vector of $24 \times 3$ parameters representing the axis-angle rotation of the 23 joints relative to their parents in the kinematic tree, plus the global orientation of the root joint (Pelvis).
  \end{enumerate}

    \item \textbf{Kinematic Tree \& Skinning} \\
    The model utilizes a hierarchical kinematic tree (e.g., the shoulder moves the elbow, which moves the wrist). The "Skin" consists of \textbf{6,890 vertices} that are bound to this skeleton using \textbf{Linear Blend Skinning (LBS)} weights. This ensures that when the skeleton moves (driven by the reconstructed angles), the skin stretches and deforms realistically, providing the necessary surface data for regeneration analysis.
  \end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{Evaluation of SMPLify reconstruction performance across varying accuracy percentiles.png}
    \caption{Evaluation of SMPLify reconstruction performance across varying accuracy percentiles}
    \label{fig:smplify_eval}
\end{figure}



\subsubsection*{HMR (Human Mesh Recovery)}
HMR utilizes a neural network to predict pose and shape coefficients from a single image in one step. This confirmed real-time skeletal reconstruction while preserving human anatomy \cite{kanazawa2018hmr}. The qualitative capabilities of this end-to-end regression are presented in Figure \ref{fig:hmr_qualitative}, demonstrating the recovery of 3D meshes from unconstrained RGB images.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{Qualitative results of Human Mesh Recovery (HMR) on unconstrained monocular RGB images.png}
    \caption{Qualitative results of Human Mesh Recovery (HMR) on unconstrained monocular RGB images}
    \label{fig:hmr_qualitative}
\end{figure}

\subsubsection{ROMP (Regressing Monocular 3D Pose and Shape)}
While SMPL provides the container for the data, ROMP is the engine used to extract that data from monocular images. It is a "one-stage" regression network designed to operate efficiently on local GPU hardware\cite{sun2021monocular}.
\begin{enumerate}[leftmargin=*]
    \item \textbf{Single-Stage Architecture} \\
    Unlike older "two-stage" methods (like SMPLify) that first detect 2D keypoints and then separately optimize a 3D model to fit them—a slow and iterative process—ROMP utilizes a ResNet-50 backbone to perform end-to-end regression. It takes an input image and simultaneously predicts the camera parameters, body center, and SMPL parameters in a single forward pass.

    \item \textbf{Pixel-Level Center Map} \\
    ROMP distinguishes itself by treating the 3D body center as a pixel-level representation. It generates a "Center Map" (heatmap) to locate subjects even in crowded scenes.

    \item \textbf{Parameter Map Construction:} For every detected body center, ROMP samples a feature vector that is decoded into:
    \begin{enumerate}[leftmargin=*]
        \item \textbf{3D Pose ($\theta$):} The rotation matrices for all 24 joints.
        \item \textbf{Body Shape ($\beta$):} The coefficients describing the user's unique anatomy.
    \end{enumerate}
  \end{enumerate}
  The complete one-stage pipeline, from the backbone feature extraction to the final parameter regression, is visualized in Figure \ref{fig:romp_architecture}, highlighting the pixel-level localization strategy.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{The ROMP One-Stage Regression Architecture for 3D Mesh Recovery.png}
    \caption{The ROMP One-Stage Regression Architecture for 3D Mesh Recovery}
    \label{fig:romp_architecture}
\end{figure}

\subsection{3D Skin Generation and Skeletal Binding}
Human digitization has evolved from primitive skeletal models to complex, mesh-based representations containing both identity and motion. Current research in 3D skin generation and skeletal binding is dominated by three major technological pillars: 

\begin{enumerate}[leftmargin=*]
    \item \textbf{Parametric Body Modeling} \\
    The most influential progression in skin creation is the \textbf{Skinned Multi-Person Linear (SMPL)} model \cite{loper2015smpl}. Other than the stick-figure skeleton model, SMPL is a vertex-based representation of simplified human bodies that provides a low-dimensional parameter space to describe human body shapes. It deforms a generic template with shape parameters $\beta$ to correspond to distinctive physical proportion and pose parameters $\theta$ that define joint rotations. The visual separation of these parameters is depicted in Figure \ref{fig:loper_smpl}, illustrating how the model mathematically decouples body shape (identity) from skeletal pose (motion).


\begin{figure}[H]
    \centering
  \includegraphics[width=0.8\textwidth]{Decomposition of the SMPL model into shape and pose parameters.png}
    \caption{Decomposition of the SMPL model into shape ($\beta$) and pose ($\theta$) parameters}
    \label{fig:loper_smpl}
\end{figure}


    \item \textbf{Automated Mesh Recovery} \\
    The alternative to manual character creation is solved with use of the so called \textbf{Human Mesh Recovery (HMR)} methods. Research by Kanazawa et al. \cite{kanazawa2018hmr} showed that it is possible to directly regress SMPL parameters from a single RGB image using end-to-end deep learning.This regression capability is visualized in \ref{fig:hmr_single_rgb}, showing the model's output on diverse input images. \textbf{Pixel-aligned Implicit Functions (PIFu)} \cite{saito2019pifu} go further in this direction, enabling digitization of "clothed" humans and obtaining high-resolution texture and clothing folds that parametric models generally fail to represent. The ability of PIFu to capture these fine-grained surface details and clothing deformations is demonstrated in \ref{fig:pifu_highres}.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Real-time 3D Human Mesh Recovery (HMR) from a single RGB image.png}
    \caption{Real-time 3D Human Mesh Recovery (HMR) from a single RGB image}
  \label{fig:hmr_single_rgb}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{High-resolution surface reconstruction using Pixel-aligned Implicit Functions (PIFu).png}
    \caption{High-resolution surface reconstruction using Pixel-aligned Implicit Functions}
  \label{fig:pifu_highres}
\end{figure}


    \item \textbf{Vertex-to-Bone Mathematical Binding} \\
    To ensure that the generated skin can deform with the skeleton without visual artifacts or slippage, Linear Blend Skinning (LBS) is used. LBS was developed as skeletal subspace deformation. While basic LBS can suffer from volume loss, the foundational work in Pose Space Deformation (\ac{PSD}) \cite{lewis2000pose} created the mathematical means to connect the weighted influence of mesh vertices to the motions of the bones. This balances the surface deformation to the active bone movements while reducing joint distortion artifacts. The improvement in volume preservation offered by this technique compared to standard skinning is illustrated in Figure \ref{fig:lbs}.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Comparison of joint volume loss in standard Linear Blend Skinning (LBS) vs. the corrected Pose Space Deformation (PSD).png}
    \caption{Comparison of joint volume loss in standard Linear Blend Skinning (LBS) vs. the corrected Pose Space Deformation}
  \label{fig:lbs}
\end{figure}
\end{enumerate}

\subsection{Validation for Accelerometer-Based Activity Reconstruction}
A primary objective of this research is to validate the proposed activity reconstruction model through a comprehensive evaluation of its accuracy, consistency, plausibility, and reliability. To ensure rigorous validation, the study utilizes a hierarchical framework consisting of four distinct levels, each targeting a specific dimension of reconstruction quality. This multi-level approach is particularly essential for accelerometer-based systems, as inherent challenges such as sensor drift and the limited observational capability of inertial measurement.

\newpage

\begin{enumerate}[leftmargin=*, itemsep=1em, label=\roman*.]

  \item \textbf{Geometric Accuracy Assessment:} \\
    Geometric validation forms the foundation of motion reconstruction evaluation, primarily relying on Euclidean distance metrics to quantify positional deviations from ground truth data obtained through optical motion capture systems\cite{zhao2025ppmotion}.
    \begin{enumerate}[leftmargin=*]
        \item \textbf{MPJPE (Mean Per Joint Position Error):} The average distance (in millimeters) between predicted and true joint coordinates.
        \item \textbf{PA-MPJPE (Procrustes-Aligned MPJPE):} This rigid alignment removes errors related to global rotation and scale, focusing purely on the "pose" structure.
        \item \textbf{PVE (Per Vertex Error):} For full avatars (meshes), this measures the error of every vertex on the body surface, capturing body shape (e.g., fat/muscle) accuracy better than just joints.
  \end{enumerate}

  \item \textbf{Physical Plausibility Verification:} \\
    Given that accelerometers fundamentally measure force-related quantities governed by Newtonian mechanics, validation must extend beyond geometric correspondence to encompass physical realism\cite{zhu2025human}.
    \begin{enumerate}[leftmargin=*]
        \item \textbf{Foot Sliding (FSR):} A critical metric for generative models. It measures the distance feet travel while they should be planted on the ground. High foot sliding is a primary indicator of poor reconstruction quality.
        \item \textbf{PhysCap \& NeuralPhysCap:} These methods validate motion by running it through a physics simulator (like MuJoCo). If the simulator cannot replicate the motion without applying impossible external forces (e.g., invisible strings pulling the puppet), the reconstruction is flagged as "implausible".
        \item \textbf{Center of Mass (CoM) Stability:} This verifies if the avatar is balanced or if it would physically fall over given the reconstructed pose.
  \end{enumerate}

  \item \textbf{Perceptual Quality Evaluation:} \\
    Recent scholarship acknowledges that mathematical accuracy does not guarantee perceptually natural motion, addressing the potential for technically correct but visually uncanny results\cite{zhao2025ppmotion}.
    \begin{enumerate}[leftmargin=*]
        \item \textbf{LPIPS (Learned Perceptual Image Patch Similarity):} A deep-learning metric used to compare rendered frames of the avatar against real video. It correlates better with human visual perception than pixel-level errors.
        \item \textbf{FID (Fréchet Inception Distance):} Measures the distance between the distribution of generated motions and real human motions. A lower FID means the motion "looks" more natural and human-like.
        \item \textbf{PP-Motion:} A newly proposed metric (2025) that combines physical constraints with human perceptual scores to give a single "Fidelity" rating.
  \end{enumerate}

  \item \textbf{Reliability and Uncertainty Quantification:} \\
    The most sophisticated validation tier addresses model confidence calibration and epistemic uncertainty. This reliability assessment is particularly pertinent for accelerometer-based systems operating in unconstrained environments where activity diversity may exceed training data coverage\cite{ponton2025step2motion}.
    \begin{enumerate}[leftmargin=*]
        \item \textbf{Expected Calibration Error (ECE)} measures the alignment between predicted confidence levels and actual accuracy rates, with elevated ECE values signaling unreliable confidence estimates.
        \item \textbf{Epistemic uncertainty quantification} identifies knowledge gaps in the model's training distribution, proving essential for detecting when the system encounters novel activities beyond its learned repertoire.
  \end{enumerate}
\end{enumerate}





\section{Gaps in Literature}
\subsection{Developing the Models using Accelerometers to Estimate the Joint Postures and the Orientations }
There are several gaps remaining in accelerometer-only based motion human activity reconstruction existing research. First, dependence on large fixed motion databases like AMASS limits the generalizationabilty and the quality of reconstruction of out-of-distribution motions as they fail to reconstruct complex and novel movements that were not present in the training data which leads to stiff motions. Second, optimization and retrieval methods being used in earlier approaches for motion reconstruction require high computational costs limiting the applicability in lightweight systems. Additionally, existing accelerometer based methods face ambiguities in rotational pose estimation and require very strong assumptions in the case of missing information when it comes to yaw rotations. The fine grained motion information, global translation estimation and adaption capability for different human morphologies and complex motions are also less represented in the existing research. These facts point towards more sophisticated methods being designed for more effective and efficient research in human activity reconstruction using accelerometers\cite{tautges2011motion}.


\subsection{Parametric Reconstruction and Anatomical Binding}
While notable progress has been achieved separately in the areas of 3D surface modeling and inertial pose estimation, effectively combining these two technologies remains a major challenge—particularly when operating with sparse sensor setups.The following sections outline the specific deficiencies in current research that this study aims to address.

\paragraph{Metric Scale and Manual Measurement Ambiguity}
Current regression-based approaches such as ROMP\cite{sun2021monocular} and HMR\cite{kanazawa2018hmr} are capable of reliably estimating 3D body shape and proportions; however, their outputs are typically expressed in a unit-less coordinate space. Most existing works focus on visual pose appearance rather than absolute metric correctness. This limitation is a major unresolved challenge for clinical applications, such as skin regeneration, where real-world measurements are essential.
Moreover, existing sparse inertial systems such as the Fast Inertial Poser\cite{xiao2024fast} still rely heavily on manual measurements. Users are required to input pre-measured limb lengths and biological parameters to properly calibrate the skeletal model. Currently there is no fully autonomous pipeline that bridges automated data derived from single-perspective visual inputs with the real-time requirements of sparse inertial sensing


\paragraph{Biometric Mismatch and Kinematic Drift}
A recurring problem in motion reconstruction is the Body Size Mismatch caused by the use of "standard" digital templates. Research shows that even slight differences between a digital skeleton’s segment lengths (e.g., the humerus)  and a user’s actual anatomy can cause the Inverse Kinematics (IK) solver to compute inaccurate joint angles\cite{molloy2023impact}. This often leads to kinematic drift and visually unrealistic artifacts, like feet sinking through the floor. Current studies do not offer a reliable method for automatically resizing a digital skeleton to match a user’s specific limb lengths using just a single-photo calibration before inertial tracking. 

\paragraph{Volume Preservation and Physiological Binding Gaps}
The final challenge lies in maintaining the visual realism of a 3D surface during extreme motions. Conventional techniques for skeletal binding, like Linear Blend Skinning (LBS), often struggle with "volume loss"\cite{lewis2000pose}. This results in joints—particularly elbows and knees—appearing to collapse or form a pinched, "candy-wrapper" effect when bent deeply. While generic corrective models exist, they fail to consider the unique muscle and soft-tissue volumes of an individual. Currently, there is no integrated approach that leverages a user’s initial photograph to guide the 3D model in realistically stretching and folding the skin according to that person’s specific anatomy.

\begin{table}[H]
\captionsetup{justification=raggedright,singlelinecheck=false}
\caption{Summary of Identified Gaps in Literature}
\small
\setlength{\tabcolsep}{4pt}
\renewcommand{\arraystretch}{1.2}
\begin{tabularx}{\textwidth}{|>{\raggedright\arraybackslash}p{3cm}|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|}
\hline
\textbf{Gap Category} & \textbf{Current Limitation} & \textbf{Impact on Reconstruction} \\ \hline
\textbf{Metric Ambiguity} & Models are unit-less and require manual height/limb entry. & Lack of clinical accuracy in skin regeneration. \\ \hline
\textbf{Biometric Mismatch} & Reliance on generic "average" skeletons. & Calculated joint angles are mathematically incorrect. \\ \hline
\textbf{Binding Artifacts} & Standard LBS causes joint collapse and volume loss. & Unrealistic visual representation during movement. \\ \hline
\end{tabularx}
\end{table}



\chapter{Methodology}


\section{Research Design}
This research follows a structured approach to human activity reconstruction. First, joint postures and orientations are estimated using sensor data and computational models. In parallel, a 3D skeletal model is reconstructed, and a virtual avatar is generated to represent human motion. These two outputs are integrated to form a complete motion representation. Finally, the proposed system is validated using experimental data, and its performance is evaluated based on accuracy, consistency, and reliability metrics. Following Figure \ref{fig:methodology_block_diagram} illustrates the proposed methodology.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Methodology Chart.png}
    \caption{Block diagram of the proposed methodology }
  \label{fig:methodology_block_diagram}
\end{figure}

\subsubsection{Estimate the joint postures and the orientations}
Since joint postures and the orientations cannot be directly obtained by only using accelerometer data, we are planning to work on different approaches at the same time as follows. Following Figure \ref{fig:estimate_joint_postures_flowchart} shows the flowchart of the estimate the joint postures and the orientations.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.87\textwidth,
    height=0.82\textheight,
    keepaspectratio]{Estimate Joint Postures.png}
    \caption{Flowchart of the Estimate the joint postures and the orientations }
  \label{fig:estimate_joint_postures_flowchart}
\end{figure}

The process commences with directly employing the available hardware components for retrieving raw data from wearable devices pertaining to the accelerometer sensor. The hardware components are solely responsible for providing initial inertial measurements to facilitate the analysis of joint posture and orientation. Wearable sensor-retrieved raw data constitutes the input for the proposed system addressing the estimation of joint posture and orientation by employing the strategy of integrating various estimation techniques.

Three parallel strategies are incorporated within the proposed architecture for estimating joint posture parameters:
\begin{enumerate}
    \item \textbf{Machine Learning Prediction:} A prediction model using machine learning algorithms has been employed for patterns within the accelerometer data and estimating joint posture and orientation information.
    \item \textbf{Geometrical Equations:} Geometrical equations for joint estimation, considering relative orientations among the sensors and gravity constraints, have been employed for joint parameter derivation.
    \item \textbf{Inverse Kinematics:} The theory of inverse kinematics for the refinement of joint orientation estimates, based on anatomical and biomechanical constraints, has been introduced.
\end{enumerate}

The parallel strategies illustrated above permit a comparative assessment and enhance the robustness of the posture estimation process. The results are assessed based on sensor accuracy, computational ability, and estimation robustness. If inadequate, the system upgrades existing elements, such as optimizing sensor locations or sampling. Once standards are satisfied, data collection and experimentation take place to accomplish a comprehensive joint posture estimation system.

\subsubsection{Avatar Generation and Animation}
In human activity reconstruction, the visualization layer must go beyond basic skeletal overlays to deliver a biologically realistic and metrically precise representation of the individual. Below Figure \ref{fig:avatar_generation_flowchart} shows the flowchart of the avatar generation and animation which we are planning to work on.  A significant limitation identified in current research is the reliance on generic skeletal models that fail to account for individual variations in limb length and body mass.The primary objective of this subsystem is to develop a unified framework that generates a personalized "Digital Twin" and animates it using a high-fidelity skin deformation pipeline. Instead of manual rigging, this research automates the transition from a 2D image to a moving 3D surface through three stages:
\\
\begin{enumerate}
    \item \textbf{Skeletal Reconstruction:} The system investigates Deep Regression methods (e.g., ROMP or HMR) to automatically predict skeletal parameters ($\theta$) and shape coefficients ($\beta$) from a single monocular image in a single pass.
    \newpage
    \item \textbf{Surface Modelling and Binding:} The avatar utilizes the Skinned Multi-Person Linear (SMPL) model, defining the surface with 6,890 vertices attached to a skeletal structure using Linear Blend Skinning (LBS).
    \item \textbf{Animation Pipeline:} A real-time processing loop receives a standardized Pose Vector ($\theta$) composed of axis-angle rotation parameters. This vector drives the LBS engine to apply rotations to the scaled skeleton with a target latency of less than 15ms .
\end{enumerate}
\begin{figure}[H]
    \centering
    \includegraphics[
    width=0.87\textwidth,
    height=0.6\textheight,
    keepaspectratio]{3D Skeletal Reconstruction.png}
    \caption{Flowchart of the Avatar Generation and Animation }
  \label{fig:avatar_generation_flowchart}
\end{figure}
\newpage
\subsubsection{Validation}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth,
    height=0.9\textheight,
    keepaspectratio
    ]{Validation.png}
    \caption{Flowchart of the Validation }
  \label{fig:validation_flowchart}
\end{figure}
In human action reconstruction, an ideal system is expected to follow a hierarchical framework comprising four distinct levels as shown in the above Figure \ref{fig:validation_flowchart}. However, to date, no existing model fully satisfies all four levels of this framework. The primary objective of our methodology is not to validate or improve an existing model, but rather to develop a new model that addresses the identified limitations in current approaches.

Therefore, instead of validating our system against an ideal but unavailable benchmark, we validate our proposed model through comparative analysis with well-established and validated models that are currently used in real-world applications. Based on our literature review, we identified several relevant models for this purpose, including

\begin{enumerate}[leftmargin=*]
    \item PP-Motion\cite{zhao2025ppmotion}
    \item EveryWear\cite{zhu2025human}
    \item Step2Motion\cite{ponton2025step2motion}
\end{enumerate}
Among these, we select a representative model that employs computer vision and image processing techniques and compare its performance with our proposed model. The comparison focuses on key evaluation criteria such as accuracy, consistency, plausibility, and reliability. This comparative validation allows us to assess the effectiveness of our approach while positioning our model within the context of existing, validated systems.

\section{Data Collection}

\subsubsection{Accelerometer Based Sensor Readings Collection}
\begin{enumerate}[leftmargin=*]
    \item Five 3-axis accelerometer sensors are placed on key body segments: both wrists, both ankles, and the torso.
    \item Each sensor measures linear acceleration along three orthogonal axes (x, y, z), including both gravitational and motion-induced acceleration.
    \item Prior to acquisition, sensor calibration corrects offset and scale errors. Sensors are securely attached to minimize relative motion.
    \item Sensor axes are aligned with anatomical reference frames, and signals are sampled at a fixed frequency as continuous time-series data.
    \item Predefined activity sets ensure consistency across data samples.
\end{enumerate}

\subsubsection{Biometric and Kinematic Data Integration}
This module defines the inputs required to build the Digital Twin:
\begin{enumerate}[leftmargin=*]
    \item \textbf{Visual Calibration Data:} A single high-resolution monocular RGB image of the subject in a neutral A-pose, resized to $512 \times 512$ pixels.
    \item \textbf{Manual Biometric Metadata:} The subject’s true height ($H_{real}$) is used for Height-Anchor Scaling to transform unit-less bone lengths into centimeter measurements.
    \item \textbf{Kinematic Interface:} The system receives 24×3 axis-angle rotation parameters from the Motion Reconstruction Module.
    \item \textbf{Synchronization:} The avatar initializes in a "Zero Pose" at $t=0$ to align the virtual skeleton and mesh with calibrated sensor orientations.
\end{enumerate}

\chapter{Timeline and Resource Required}
\section{Timeline}
\begin{figure}[H]
    \centering
  \includegraphics[width=0.77\textwidth]{Timeline.png}
    \caption{TimeLine }
    \label{fig:timeline}
\end{figure}


\section{Resource Required}
This is a general estimation of budget for this project. These prices can be vary since the exact electronics/ services are not decided yet.

\begin{table}[H]
    \centering
    \caption{Estimated Budget for Project Components and Services}
    \label{tab:project_budget}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{No} & \textbf{Item / Service} & \textbf{price} \\ \hline
        1 & Repair for existing components & 5 000 \\ \hline
        2 & Web hosting & 15 000 \\ \hline
        3 & ML training platform & 8 000 \\ \hline
        4 & Cloud computing & 20 000 \\ \hline
        5 & API s & 10 000 \\ \hline
          & \textbf{Total} & \textbf{58 000} \\ \hline
    \end{tabular}
\end{table}



\chapter{Conclusion}
\noindent This project proposal offers a framework for accomplishing accurate human activity recognition using a sparse sensor configuration of five 3-axis accelerometers. Through the placement of the sensors at the wrist, ankle, and torso, the proposed approach meets the requirement for developing a non-invasive and portable solution for human activity recognition, which requires lower costs compared to the usual motion capture systems that are dense, expensive, and complex. \vspace{\baselineskip}


\noindent The approach systematically investigates three different estimation techniques in parallel to connect raw inertial measurements with realistic visualization. They are pattern recognition through machine-learning techniques, orientation equations in geometry, and inverse kinematics theories. The combination of different techniques can improve the reliability of joint posture and orientation estimation in the presence of ambiguities in raw accelerometer data.\vspace{\baselineskip}


\noindent One of the key contributions of the above-mentioned research is the creation of a personalized “Digital Twin” using an “automatic three-dimensional avatar generation pipeline.” The process eliminates the need for generic digital templates and manual measurements in place and uses deep regression techniques like \ac{ROMP} or \ac{HMR} in conjunction with the Skinned Multi-Person Linear (\ac{SMPL}) model, thereby achieving metric accuracy and realistic skin deformation while avoiding joint volume loss and kinematic drift problems. \vspace{\baselineskip}


\noindent Finally, the solution also applies an effective four-tier validation mechanism that takes into account the geometric, physical, perceptual, and reliability verification to ensure the performance of the system aligns well with the expectations in the real world. This project’s effective inte-
gration of sparse inertial sensing with advanced computer vision and biomechanical modeling, results in a scalable and efficient solution for applications in healthcare,
sports analysis, and immersive virtual environments. \vspace{\baselineskip}



% References
\renewcommand{\bibname}{References}
\bibliographystyle{ieeetr}
\addcontentsline{toc}{chapter}{References} % Add to table of contents
\bibliography{bibliography} 
%\printbibliography

\end{document}